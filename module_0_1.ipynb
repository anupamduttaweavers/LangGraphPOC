{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba23d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langgraph langsmith langchain_core langchain_community langchain_openai python-dotenv jupyterlab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc67fc5d-9efb-4d6f-9abe-8ffb8812c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: model\n",
      "\n",
      "Hi!\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: System\n",
      "\n",
      "You are a usefull model to answer\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: human\n",
      "\n",
      "I am good\n"
     ]
    }
   ],
   "source": [
    "#Exploring messages from langchain_core.messages AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content=\"Hi!\",name=\"model\")]\n",
    "messages.extend([SystemMessage(content=\"You are a usefull model to answer\", name=\"System\")])\n",
    "messages.extend([HumanMessage(content=\"I am good\", name=\"human\")])\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b10aeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "219c8697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_cb9MuUZ2effcF5aG3pHzKZPV', 'function': {'arguments': '{\"a\":5,\"b\":7}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 109, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BLtlmhiD6B7zdFQ2QOkTp7kf49crB', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-2d12c302-34a8-44c0-a04e-d818f1b5407a-0' tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 7}, 'id': 'call_cb9MuUZ2effcF5aG3pHzKZPV', 'type': 'tool_call'}] usage_metadata={'input_tokens': 109, 'output_tokens': 18, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Ctreating llm\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "llm = init_chat_model(model='gpt-4o',model_provider='openai')\n",
    "\n",
    "#creating tools\n",
    "\n",
    "@tool\n",
    "def multiply(a:int, b:int):\n",
    "    \"\"\" This function will calculate multiplication of given value\n",
    "    Args:\n",
    "         a : first input as typed int\n",
    "         b : second input as typed int\n",
    "\n",
    "    return: multipication of two numbers\n",
    "\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# initilize tool caling llm\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "messages = [SystemMessage(content=\"Hi! you are a helpfull llm please use the multiply tool if you ask for perform multiplication\", name=\"System\")]\n",
    "messages.extend([HumanMessage(content=\"Please multiply 5 and 7\", name=\"Human\")])\n",
    "\n",
    "responce = llm_with_tools.invoke(messages)\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d69711c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#State with list of messages\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated, TypedDict, List\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "# As this thing frequenty used in langgraph we have prebuild class for the above ,\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    #messages key pre-installed\n",
    "    pass\n",
    "\n",
    "# define node\n",
    "\n",
    "def call_tool_llm(state:MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke(state[\"messages\"])}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"call_tool_llm\", call_tool_llm)\n",
    "builder.add_edge(START,\"call_tool_llm\")\n",
    "builder.add_edge(\"call_tool_llm\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed670be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Response from tool-bound LLM: content='' additional_kwargs={'tool_calls': [{'id': 'call_Gp5hxMgKgV3yA2opzbAn1JIb', 'function': {'arguments': '{\"a\":5,\"b\":7}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 71, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_432e014d75', 'id': 'chatcmpl-BLutJaZnAz2tTnWTT3U7LUFCix6R8', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d48f2810-e555-4852-8c2a-644eba33a33c-0' tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 7}, 'id': 'call_Gp5hxMgKgV3yA2opzbAn1JIb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 71, 'output_tokens': 18, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'messages': [HumanMessage(content='multiplication of 10 and 5', additional_kwargs={}, response_metadata={}, id='a8ef268b-a75e-429b-956a-4016bbf1af1a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iNoX6tso3nrRiz6IZ3aeThS6', 'function': {'arguments': '{\"a\":10,\"b\":5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 52, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BLutKbeeHhbg5mWnsnsWO6i6lja6d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bad69e79-450d-4acc-bfb5-56efa07405fd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 10, 'b': 5}, 'id': 'call_iNoX6tso3nrRiz6IZ3aeThS6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 52, 'output_tokens': 18, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating LLM\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AnyMessage\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, TypedDict, List\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Initialize the chat model with tools support\n",
    "llm = init_chat_model(model='gpt-4o', model_provider='openai')\n",
    "\n",
    "# 2. Creating a tool\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# 3. Bind the tool to the model\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "# 4. Prepare a basic test (optional, just to see it working)\n",
    "messages = [\n",
    "    SystemMessage(content=\"Hi! You are a helpful LLM. Please use the multiply tool if asked to perform multiplication.\"),\n",
    "    HumanMessage(content=\"Please multiply 5 and 7\")\n",
    "]\n",
    "response = llm_with_tools.invoke(messages)\n",
    "print(\"Direct Response from tool-bound LLM:\", response)\n",
    "\n",
    "# 5. Define LangGraph State (Optional since MessagesState already exists)\n",
    "# You do not need this class unless youâ€™re customizing the state\n",
    "# Keeping it to match your original structure, but it's optional\n",
    "class CustomMessagesState(MessagesState):\n",
    "    pass\n",
    "\n",
    "# 6. Define a node function\n",
    "def call_tool_llm(state: MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke(state[\"messages\"])}\n",
    "\n",
    "# 7. Build the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_tool_llm\", call_tool_llm)\n",
    "builder.add_edge(START, \"call_tool_llm\")\n",
    "builder.add_edge(\"call_tool_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "print(graph.invoke({\"messages\":\"multiplication of 10 and 5\"}))\n",
    "# # 8. Visualize the graph\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd4deaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "5+ 5 \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "5 + 5 equals 10.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.tools import tool\n",
    "\n",
    "#llm\n",
    "llm = init_chat_model(model=\"gpt-4o\", model_provider='openai')\n",
    "\n",
    "#build tools\n",
    "@tool\n",
    "def multiply(a:int, b:int):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "@tool\n",
    "def summ(a:int, b:int):\n",
    "    \"\"\"Sum or Add two integers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply, sum])\n",
    "\n",
    "def call_tool_llm(state:MessagesState):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"call_tool_llm\", call_tool_llm)\n",
    "builder.add_node(\"tools\",ToolNode([multiply]))\n",
    "builder.add_edge(START, \"call_tool_llm\")\n",
    "builder.add_conditional_edges(\"call_tool_llm\",tools_condition)\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "messages = graph.invoke({\"messages\":\"5+ 5 \"})\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
